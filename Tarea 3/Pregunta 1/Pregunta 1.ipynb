{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Viejo XOR: Metodos No-lineales para Problemas No-lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta sección es experimentar con algunos modelos no-lineales sobre un problema de juguete,\n",
    "pero bastante famoso en la historia del aprendizaje automático, que denominaremos XOR. Se trata de un\n",
    "problema de clasificación a todas luces linealmente inseparable, en el sentido que, si denotamos por x ∈ R 2\n",
    "un patrón de entrada y por y ∈ {0,1} su correspondiente etiqueta, no existen w ∈ R 2 ,b ∈ R tal que\n",
    "y(w T x+b) ≥ ρ > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](enunciado.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Escriba una función que genere (aleatoriamente) n datos etiquetados de la forma {(x 1 ,y 1 ),...,(x n ,y n )}, x i ∈ R 2 , y i ∈ {0,1}, con una distribución de probabilidad que refleje la configuración linealmente inseparable que muestra la Fig.1. Utilice esta función para crear 1000 datos de entrenamiento y 1000 datos de pruebas. Para medir la tendencia de los modelos a sobre-ajuste, agregue un 10% de ruido al dataset de entrenamiento, generando x’s cercanos a la frontera e invirtiendo la etiqueta correcta de este subconjunto. Genere in gráfico que muestre sus datos de entrenamiento y pruebas, identificando cada\n",
    "clase con un color diferente. ¿Porque tiene sentido denominar este problema XOR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def do_XOR(n=1000,noisy_n=100,svm=True):\n",
    "    rng = np.random.RandomState(0)\n",
    "    X_train = rng.uniform(low=-1.0,high=1.0,size=(n,2))\n",
    "    Y_train = np.logical_xor(X_train[:,0] > 0, X_train[:,1] > 0)\n",
    "    Y_train = 2*Y_train-1 if svm else Y_train\n",
    "    X_noisy= rng.uniform(low=-0.8,high=0.2,size=(noisy_n,2))\n",
    "    Y_noisy = -1*np.logical_xor(X_noisy[:,0] > 0, X_noisy[:,1] > 0) + 1\n",
    "    Y_noisy = 2*Y_noisy-1 if svm else Y_noisy\n",
    "    X_train = np.vstack((X_train, X_noisy))\n",
    "    Y_train = np.hstack((Y_train, Y_noisy))\n",
    "    X_test = rng.uniform(low=-1.0,high=1.0,size=(n,2))\n",
    "    Y_test = np.logical_xor(X_test[:,0] > 0, X_test[:,1] > 0)\n",
    "    Y_test = 2*Y_test - 1 if svm else Y_test\n",
    "    return X_train,Y_train,X_test,Y_test\n",
    "\n",
    "X_train,Y_train,X_test,Y_test = do_XOR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Demuestre _experimentalmente_ que una SVM lineal no puede resolver satisfactoriamente el problema\n",
    "anterior. Sea convincente: por ejemplo, intente modificar los parámetros de la máquina de aprendizaje, reportando m´ etricas que permitan evaluar el desempe˜ no del modelo en el problema. Escriba tambien una función, denominada plot classifier que represente gráficamente la solución encontrada por la máquina de aprendizaje, representando los datos de entrenamiento y pruebas (asociando un color a la clase que les corresponde), además de la frontera de clasificación. Describa y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_classifier(clf,X_train,Y_train,X_test,Y_test,model_type):\n",
    "    f, axis = plt.subplots(1, 1, sharex='col', sharey='row',figsize=(20, 20))\n",
    "    axis.scatter(X_train[:,0],X_train[:,1],s=5,c=Y_train,zorder=10,cmap='gray')\n",
    "    axis.scatter(X_test[:,0],X_test[:,1],s=15,c=Y_test,zorder=10,cmap='gray')\n",
    "    XX, YY = np.mgrid[-1:1:200j, -1:1:200j]\n",
    "    if model_type == 'svm':\n",
    "        Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "    elif model_type == 'tree':\n",
    "        Z = clf.predict_proba(np.c_[XX.ravel(), YY.ravel()])[:,0]\n",
    "    elif model_type == 'ann':\n",
    "        Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "    else: raise ValueError('model type not supported')\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    Zplot = Z > 0 if model_type == 'svm' else Z > 0.5\n",
    "    axis.pcolormesh(XX, YY, Zplot ,cmap='YlGn')\n",
    "    axis.contour(XX, YY, Z, alpha=1, colors=['k', 'k', 'k'],\n",
    "    linestyles=['--', '-', '--'],levels=[-1, 0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ Demuestre _experimentalmente_ que una SVM con kernel no-lineal puede resolver satisfactoriamente el problema. Para esta actividad, use los hiper-parámetros que se entregan como referencia en el código de ejemplo (muestre resultados tanto para el kernel Polynomial como para el kernel RBF). Cambie el valor del parámetro C eligiendo κ en el intervalo [−2,4] (con saltos de 1 unidad) y asignando al parámetro el valor C = 2 κ . Describa y explique lo que observa, graficando el error de entrenamiento y pruebas como función de C. Utilice la función _plot classifier_, diseñada en el item anterior, para construir gráficos de la solución con distintos valores de C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=100, kernel='rbf')\n",
    "clf = SVC(C=10, kernel='poly',degree=2, coef0=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print \"Test Accuracy = %f\"%clf.score(X_test,Y_test)\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d)__ Demuestre _experimentalmente_ que una red neuronal artificial correspondiente a 1 sola neurona (i.e. sin capas escondidas) no puede resolver satisfactoriamente el problema. Puede utilizar la función de activación y el metodo de entrenamiento que prefiera. Sea convincente: por ejemplo, intente modificar los parámetros de la máquina de aprendizaje, reportando metricas que permitan evaluar el desempe˜ no del modelo en el problema con cada cambio efectuado. Adapte tambien la función _plot classifier_ para que represente gráficamente la solución encontrada por la red neuronal. Describa y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "n_h=1\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(n_h, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, nb_epoch=50, batch_size=100, verbose=1)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__e)__ Demuestre experimentalmente que una red neuronal artificial con 1 capa escondida puede resolver satis- factoriamente el problema obtenido en (a). Puede utilizar la arquitectura y el m´ etodo de entrenamiento que prefiera, pero en esta actividad puede optar tranquilamente por usar los hiper-parámetros que se entregan como referencia en el código de ejemplo. Cambie el número de neuronas N h en la red entre 2 y 32 en potencias de 2, graficando el error de entrenamiento y pruebas como función de N h . Describa y explique lo que observa. Utilice la función plot classifier, dise˜ nada anteriormente, para construir gráficos de la solución en algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#...\n",
    "n_h=8\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(n_h, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__f)__ Demuestre _experimentalmente_ que stump (árbol de clasificación de 1 nivel) no puede resolver satisfactoriamente el problema anterior. Puede utilizar el criterio y la función de partición que prefiera. Sea convincente: por ejemplo, intente modificar los parámetros de la máquina, reportando m´ etricas que permitan evaluar el desempe˜ no del modelo en el problema con cada cambio efectuado. Adapte tambien la función plot classifier para que represente gráficamente la solución encontrada por el árbol. Describa y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "clf=Tree(criterion='gini',splitter='best',random_state=0,max_depth=1)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__g)__ Demuestre _experimentalmente_ que un árbol de clasificación de múltiples niveles puede resolver satisfactoriamente el problema estudiado. Puede utilizar el criterio y la función de partición que prefiera, pero puede optar tranquilamente por usar los hiper-parámetros que se entregan como referencia en el código de ejemplo. Cambie el número de niveles admitidos en el árbol N t entre 2 y 20, graficando el error de entrenamiento y pruebas como función de N t . Describa y explique lo que observa. Utilice la función plot classifier, dise˜ nada anteriormente, para construir gráficos de la solución en algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#...\n",
    "n_t=8\n",
    "clf=Tree(criterion='gini',splitter='best',random_state=0,max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
