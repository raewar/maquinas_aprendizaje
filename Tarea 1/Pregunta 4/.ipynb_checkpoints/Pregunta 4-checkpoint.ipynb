{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from urllib import urlretrieve\n",
    "\n",
    "url = 'http://octopus.inf.utfsm.cl/~ricky/movies.tar.gz'\n",
    "\n",
    "filename, headers = urlretrieve(url, 'movies.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(filename)\n",
    "\n",
    "dev_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/dev.x.mm\"\n",
    "test_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/test.x.mm\"\n",
    "dev_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/dev.y.dat\"\n",
    "test_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/test.y.dat\"\n",
    "train_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/train.x.mm\"\n",
    "train_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/train.y.dat\"\n",
    "vocab = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/vocab\"\n",
    "\n",
    "dev_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/dev.x.mm\"\n",
    "test_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/test.x.mm\"\n",
    "dev_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/dev.y.dat\"\n",
    "test_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/test.y.dat\"\n",
    "train_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/train.x.mm\"\n",
    "train_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/train.y.dat\"\n",
    "vocab_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/vocab\"\n",
    "\n",
    "for tarinfo in tar:\n",
    "\n",
    "    if tarinfo.name == dev_x:\n",
    "        d_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == dev_y:\n",
    "        d_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_x:\n",
    "        t_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_y:\n",
    "        t_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_x:\n",
    "        tr_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_y:\n",
    "        tr_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == vocab:\n",
    "        v = tar.extractfile(tarinfo.name)\n",
    "        \n",
    "    if tarinfo.name == dev_x_stars:\n",
    "        d_x_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == dev_y_stars:\n",
    "        d_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_x_stars:\n",
    "        t_x_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_y_stars:\n",
    "        t_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_x_stars:\n",
    "        tr_x_s = tar.extractfile(tarinfo.name)    \n",
    "    if tarinfo.name == train_y_stars:\n",
    "        tr_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == vocab_stars:\n",
    "        v_s = tar.extractfile(tarinfo.name)\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "v_array = v.read().split(\"\\n\")\n",
    "v_s_array = v_s.read().split(\"\\n\")\n",
    "\n",
    "d_y_array = np.loadtxt(d_y)\n",
    "t_y_array = np.loadtxt(t_y)\n",
    "tr_y_array = np.loadtxt(tr_y)\n",
    "d_y_s_array = np.loadtxt(d_y_s)\n",
    "t_y_s_array = np.loadtxt(t_y_s)\n",
    "tr_y_s_array = np.loadtxt(tr_y_s)\n",
    "\n",
    "d_x_matrix = csr_matrix(sio.mmread(d_x))\n",
    "t_x_matrix = csr_matrix(sio.mmread(t_x))\n",
    "tr_x_matrix = csr_matrix(sio.mmread(tr_x))\n",
    "\n",
    "d_x_s_matrix = csr_matrix(sio.mmread(d_x_s))\n",
    "t_x_s_matrix = csr_matrix(sio.mmread(t_x_s))\n",
    "tr_x_s_matrix = csr_matrix(sio.mmread(tr_x_s))\n",
    "\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante mantener el formato __sparse__ de las matrices, por un tema de optimización de memoria. Es necesario tener solo en memoria los datos no nulos de la matriz. Esto es significativo cuando se trabaja con matrices muy grandes, y donde muchos de los elementos son nulos. Asi, con un formato __sparse__, no hay necesidad de desperdiciar memoria en datos que no estan, haciendo mas eficiente el procesamiento de estas matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo a utilizar\n",
    "En esta ocación, el modelo a utilizar para modelar este problema es el _ElasticNet_, propuesto en el paper _\"Movie Reviews and Revenues: An Experiment in Text Regression\"_. Es una regresion lineal que combina la norma L1 y L2. Es un hibrido entre las penalizaciones de _Ridge_ y _Lasso_. Para un $\\alpha = 0$, equivale a utilizar _Ridge_ y $\\alpha = 1$ a _Lasso_. \n",
    "\n",
    "$$\\theta = argmin \\frac{1}{2n} \\sum_{i=1}^{n}{(y_i-(\\beta_0 + x^T_i\\beta) )^2 + \\lambda P(\\beta)}$$\n",
    "$$P(\\beta) = \\sum_{j=1}^p (\\frac{1}{2} (1-\\beta) \\beta_j^2+\\alpha |\\beta_j|)$$\n",
    "\n",
    "Para estimar los mejores parametros, utilizando los datos de entrenamiento, se fueron variando los valores de \\alpha y \\lambda, evaluando la funcion sobre los datos de desarrollo. A medida que se consige un mejor coeficiente de ajuste, se van guardando los paramentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_params_dev():\n",
    "    ratio = np.arange(0.,1.2,0.2)\n",
    "    alfa = np.logspace(-2, 1, num=30, base=10)\n",
    "    model = ElasticNet(fit_intercept = False)\n",
    "    best_a = 0\n",
    "    best_b = 0\n",
    "    best_coef = 0\n",
    "    for b in ratio:\n",
    "        for a in alfa:\n",
    "            model.set_params(alpha = a, l1_ratio = b)\n",
    "            model.fit(tr_x_matrix, tr_y_array)\n",
    "            coef = model.score(d_x_matrix, d_y_array)\n",
    "            if best_coef < coef:\n",
    "                best_coef = coef\n",
    "                best_a = a\n",
    "                best_b = b\n",
    "    return a,b\n",
    "\n",
    "a,b = best_params_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ElasticNet(fit_intercept = False)\n",
    "model.set_params(alpha = a, l1_ratio = b)\n",
    "model.fit(tr_x_matrix, tr_y_array)\n",
    "\n",
    "print \"R2=%f\"%model.score(t_x_matrix, t_y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
