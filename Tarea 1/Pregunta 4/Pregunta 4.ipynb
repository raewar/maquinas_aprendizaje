{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from urllib import urlretrieve\n",
    "\n",
    "url = 'http://octopus.inf.utfsm.cl/~ricky/movies.tar.gz'\n",
    "\n",
    "filename, headers = urlretrieve(url, 'movies.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(filename)\n",
    "\n",
    "dev_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/dev.x.mm\"\n",
    "test_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/test.x.mm\"\n",
    "dev_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/dev.y.dat\"\n",
    "test_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/test.y.dat\"\n",
    "train_x = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/train.x.mm\"\n",
    "train_y = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/train.y.dat\"\n",
    "vocab = \"movies-preproc/ngrams-deprels-origin.runtime.budget.numscreen.ratings.seasons/vocab\"\n",
    "\n",
    "dev_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/dev.x.mm\"\n",
    "test_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/test.x.mm\"\n",
    "dev_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/dev.y.dat\"\n",
    "test_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/test.y.dat\"\n",
    "train_x_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/train.x.mm\"\n",
    "train_y_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/train.y.dat\"\n",
    "vocab_stars = \"movies-preproc/ngrams-deprels-fp1-origin.runtime.budget.numscreen.ratings.seasons.stars/vocab\"\n",
    "\n",
    "for tarinfo in tar:\n",
    "\n",
    "    if tarinfo.name == dev_x:\n",
    "        d_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == dev_y:\n",
    "        d_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_x:\n",
    "        t_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_y:\n",
    "        t_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_x:\n",
    "        tr_x = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_y:\n",
    "        tr_y = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == vocab:\n",
    "        v = tar.extractfile(tarinfo.name)\n",
    "        \n",
    "    if tarinfo.name == dev_x_stars:\n",
    "        d_x_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == dev_y_stars:\n",
    "        d_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_x_stars:\n",
    "        t_x_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == test_y_stars:\n",
    "        t_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == train_x_stars:\n",
    "        tr_x_s = tar.extractfile(tarinfo.name)    \n",
    "    if tarinfo.name == train_y_stars:\n",
    "        tr_y_s = tar.extractfile(tarinfo.name)\n",
    "    if tarinfo.name == vocab_stars:\n",
    "        v_s = tar.extractfile(tarinfo.name)\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "v_array = v.read().split(\"\\n\")\n",
    "v_s_array = v_s.read().split(\"\\n\")\n",
    "\n",
    "d_y_array = np.loadtxt(d_y)\n",
    "t_y_array = np.loadtxt(t_y)\n",
    "tr_y_array = np.loadtxt(tr_y)\n",
    "d_y_s_array = np.loadtxt(d_y_s)\n",
    "t_y_s_array = np.loadtxt(t_y_s)\n",
    "tr_y_s_array = np.loadtxt(tr_y_s)\n",
    "\n",
    "d_x_matrix = csr_matrix(sio.mmread(d_x))\n",
    "t_x_matrix = csr_matrix(sio.mmread(t_x))\n",
    "tr_x_matrix = csr_matrix(sio.mmread(tr_x))\n",
    "\n",
    "d_x_s_matrix = csr_matrix(sio.mmread(d_x_s))\n",
    "t_x_s_matrix = csr_matrix(sio.mmread(t_x_s))\n",
    "tr_x_s_matrix = csr_matrix(sio.mmread(tr_x_s))\n",
    "\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante mantener el formato __sparse__ de las matrices, por un tema de optimización de memoria. Es necesario tener solo en memoria los datos no nulos de la matriz. Esto es significativo cuando se trabaja con matrices muy grandes, y donde muchos de los elementos son nulos. Asi, con un formato __sparse__, no hay necesidad de desperdiciar memoria en datos que no estan, haciendo mas eficiente el procesamiento de estas matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo a utilizar\n",
    "En esta ocación, el modelo a utilizar para modelar este problema es el _ElasticNet_, propuesto en el paper _\"Movie Reviews and Revenues: An Experiment in Text Regression\"_. Es una regresion lineal que combina la norma L1 y L2. Es un hibrido entre las penalizaciones de _Ridge_ y _Lasso_. Para un $\\alpha = 0$, equivale a utilizar _Ridge_ y $\\alpha = 1$ a _Lasso_. \n",
    "\n",
    "$$\\theta = argmin \\frac{1}{2n} \\sum_{i=1}^{n}{(y_i-(\\beta_0 + x^T_i\\beta) )^2 + \\lambda P(\\beta)}$$\n",
    "$$P(\\beta) = \\sum_{j=1}^p (\\frac{1}{2} (1-\\beta) \\beta_j^2+\\alpha |\\beta_j|)$$\n",
    "\n",
    "Para estimar los mejores parametros, utilizando los datos de entrenamiento, se fueron variando los valores de \\alpha y \\lambda, evaluando la funcion sobre los datos de desarrollo. A medida que se consige un mejor coeficiente de ajuste, se van guardando los paramentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def best_params_dev(b):\n",
    "    alfa = np.logspace(-2, 1, num=30, base=10)\n",
    "    model = ElasticNet(fit_intercept = False)\n",
    "    best_a = 0\n",
    "    best_b = 0\n",
    "    best_coef = 0\n",
    "\n",
    "    for a in alfa:\n",
    "        model.set_params(alpha = a, l1_ratio = b)\n",
    "        model.fit(tr_x_matrix, tr_y_array)\n",
    "        coef = model.score(d_x_matrix, d_y_array)\n",
    "        if best_coef < coef:\n",
    "            best_coef = coef\n",
    "            best_a = a\n",
    "            best_b = b\n",
    "    print \"Para b: {0}, el mejor a: {1} con un coeficiente de {2}\".format(best_b, best_a, best_coef)        \n",
    "    \n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a0,b0 = best_params_dev(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para b: 0.25, el mejor a: 10.0 con un coeficiente de 0.249260599215\n"
     ]
    }
   ],
   "source": [
    "a1,b1 = best_params_dev(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-38ecc1dcb23f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_params_dev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-1fbad23fa122>\u001b[0m in \u001b[0;36mbest_params_dev\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malfa\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_x_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_y_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbest_coef\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    702\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                           check_input=False)\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.pyc\u001b[0m in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_sparse_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                 max_iter, tol, rng, random, positive)\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a2,b2 = best_params_dev(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a3,b3 = best_params_dev(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a4,b4 = best_params_dev(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ElasticNet(fit_intercept = False)\n",
    "model.set_params(alpha = a, l1_ratio = b)\n",
    "model.fit(tr_x_matrix, tr_y_array)\n",
    "\n",
    "print \"R2=%f\"%model.score(t_x_matrix, t_y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.,1.2,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
